<!DOCTYPE html>
<html lang="zh">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>GLM-4-Voice 异步语音对话单页应用</title>
    <style>
        body { font-family: Arial, sans-serif; max-width: 800px; margin: 0 auto; padding: 20px; }
        h1 { text-align: center; }
        #chat { height: 400px; overflow-y: scroll; border: 1px solid #ccc; padding: 10px; margin-bottom: 20px; background: #f9f9f9; }
        .message { margin: 10px 0; padding: 10px; border-radius: 8px; }
        .user { background: #dcf8c6; align-self: flex-end; }
        .assistant { background: #fff; }
        .audio-controls { margin-top: 10px; }
        button { padding: 10px 20px; font-size: 16px; margin: 0 10px; }
        #apiKey { width: 100%; padding: 10px; margin-bottom: 20px; }
        #status { color: red; font-weight: bold; }
    </style>
</head>
<body>
    <h1>GLM-4-Voice 语音消息对话</h1>
    <p>这是一个基于智谱AI GLM-4-Voice模型的单页语音对话应用。支持录音输入、异步发送、自动播放AI回复语音，并显示文本转录。</p>
    <p>注意：当前官方API为同步调用（非实时流式），每轮对话需完整录音后发送。模型支持语音理解与生成。</p>
    
    <label>您的智谱AI API Key：</label>
    <input type="password" id="apiKey" placeholder="请输入您的API Key（从 https://open.bigmodel.cn/ 获取）">

    <div id="status"></div>

    <div id="chat"></div>

    <button id="startRecord">开始录音</button>
    <button id="stopRecord" disabled>停止录音并发送</button>

    <script>
        let mediaRecorder;
        let audioChunks = [];
        let conversationHistory = []; // 存储多轮对话历史（仅文本+audio base64）

        const apiKeyInput = document.getElementById('apiKey');
        const status = document.getElementById('status');
        const chat = document.getElementById('chat');
        const startBtn = document.getElementById('startRecord');
        const stopBtn = document.getElementById('stopRecord');

        startBtn.onclick = async () => {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                mediaRecorder = new MediaRecorder(stream);
                audioChunks = [];

                mediaRecorder.ondataavailable = e => audioChunks.push(e.data);
                mediaRecorder.onstop = () => stream.getTracks().forEach(track => track.stop());

                mediaRecorder.start();
                startBtn.disabled = true;
                stopBtn.disabled = false;
                status.textContent = '正在录音...';
            } catch (err) {
                status.textContent = '无法访问麦克风：' + err.message;
            }
        };

        stopBtn.onclick = async () => {
            mediaRecorder.stop();
            startBtn.disabled = false;
            stopBtn.disabled = true;
            status.textContent = '处理中...';

            const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
            const base64Audio = await blobToBase64(audioBlob);

            // 添加用户消息（显示正在转录）
            addMessageToChat('user', '（您的语音消息） <audio controls src="' + URL.createObjectURL(audioBlob) + '"></audio>');

            // 调用API
            const apiKey = apiKeyInput.value.trim();
            if (!apiKey) {
                status.textContent = '请先输入API Key！';
                return;
            }

            const response = await fetch('https://open.bigmodel.cn/api/paas/v4/chat/completions', {
                method: 'POST',
                headers: {
                    'Authorization': `Bearer ${apiKey}`,
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify({
                    model: 'glm-4-voice',
                    messages: [
                        ...conversationHistory,
                        {
                            role: 'user',
                            content: [
                                { type: 'text', text: '' }, // 可选附加文本指令，如"请用开心语气回复"
                                {
                                    type: 'input_audio',
                                    input_audio: {
                                        data: base64Audio.replace(/^data:audio\/\w+;base64,/, ''), // 去除前缀
                                        format: 'wav'
                                    }
                                }
                            ]
                        }
                    ],
                    stream: false // 当前文档示例为非流式
                })
            });

            if (!response.ok) {
                const err = await response.json();
                status.textContent = 'API错误：' + (err.error?.message || response.statusText);
                return;
            }

            const data = await response.json();
            const assistantMsg = data.choices[0].message;

            // 更新历史（只存文本和audio，audio仅本次）
            conversationHistory.push({
                role: 'user',
                content: [{ type: 'input_audio', input_audio: { data: base64Audio.replace(/^data:audio\/\w+;base64,/, ''), format: 'wav' } }]
            });
            conversationHistory.push({
                role: 'assistant',
                content: assistantMsg.content // 文本
                // audio 在响应中单独字段
            });

            // 显示AI文本
            let text = assistantMsg.content || '（无文本回复）';

            // 处理AI语音
            if (assistantMsg.audio && assistantMsg.audio.data) {
                const audioBase64 = assistantMsg.audio.data;
                const audioBlobAi = base64ToBlob(audioBase64, 'audio/wav');
                const audioUrl = URL.createObjectURL(audioBlobAi);

                addMessageToChat('assistant', text + '<div class="audio-controls"><audio controls autoplay src="' + audioUrl + '"></audio></div>');
            } else {
                addMessageToChat('assistant', text + '（无语音回复）');
            }

            status.textContent = '就绪';
        };

        function addMessageToChat(role, content) {
            const div = document.createElement('div');
            div.className = 'message ' + role;
            div.innerHTML = '<strong>' + (role === 'user' ? '您' : 'AI') + '：</strong>' + content;
            chat.appendChild(div);
            chat.scrollTop = chat.scrollHeight;
        }

        function blobToBase64(blob) {
            return new Promise((resolve, reject) => {
                const reader = new FileReader();
                reader.onload = () => resolve(reader.result);
                reader.onerror = reject;
                reader.readAsDataURL(blob);
            });
        }

        function base64ToBlob(base64, type) {
            const binary = atob(base64);
            const array = [];
            for (let i = 0; i < binary.length; i++) {
                array.push(binary.charCodeAt(i));
            }
            return new Blob([new Uint8Array(array)], { type });
        }
    </script>
</body>
</html>